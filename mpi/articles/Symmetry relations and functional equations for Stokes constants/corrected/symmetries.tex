\documentclass[12pt]{iopart}
\usepackage{bm}
\usepackage{graphicx}
\usepackage{cite}

\def\S{\widehat{S}}
\def\W{\widehat{W}}
\def\C{\widehat{C}}
\def\f{\hat{f}}
\def\g{\hat{g}}
\def\h{\hat{h}}
\def\psii{\bm\psi}
\def\L{\widehat{L}}
\def\lmbd{\bm{\lambda}}
\def\Tp{\mathrm{T}}
\def\unity{\hat{\it 1}}
\def\Re{\mathrm{Re}}
\def\Im{\mathrm{Im}}
\def\w{\omega}
\def\T{\widehat{T}_{fgh}}

\newcommand\phsintgrnd[1][z]{q(#1,\lmbd)}
\newcommand\predexp[1][z]{q(#1,\lmbd)^{-1/2}}
\newcommand\phsintgrl[3][z]{\int_{#2}^{#3} \phsintgrnd[#1] \rmd #1}

\begin{document}
\title[Effective Stokes diagram and symmetry relations for effective Stokes constants]{Effective Stokes diagram, symmetry relations and functional equations for effective Stokes constants}
\author{Anton Kutlin}

\address{Institute of Applied Physics of Russian Academy of Sciences, 46 Ulyanov str., 603950 Nizhny Novgorod, Russia}
\ead{anton.kutlin@gmail.com}


\date{\today}

\begin{abstract}
We consider an arbitrary ordinary linear differential equation of the second order and study 
how its symmetries affect the Stokes constants associated with its general solution. 
We reformulate the well-known Heading's rules for analytical continuation in a matrix form 
and propose a concept of an effective Stokes diagram. We show that each effective Stokes 
domains which can be overlaid by a symmetry transformation are associated with the same 
effective Stokes constant and can be described by the same analytical function. Basing on
the derived symmetry relations we propose a way to write functional equations for 
the effective Stokes constants. This work also contains an example of possible usage 
of the presented ideas in a case of a real physical problem.
\end{abstract}

\pacs{02.30.Hq,02.30.Mv}
\submitto{\jpa}

\noindent{\it Keywords\/}:phase-integral method, Stokes phenomenon, Stokes constants, connection matrixes

%\maketitle

\section{Introduction \label{sec:intro}}
Consider a stationary one-dimensional Schr\"odinger equation
\begin{eqnarray}
\frac{\rmd^2 y(z,\lmbd)}{\rmd z^2} + Q(z,\lmbd)y(z,\lmbd) = 0,   \label{eq:gen}
\end{eqnarray}
where $\lmbd$ is a set of the problem`s parameters. Throughout the paper 
\mbox{$Q(z,\lmbd)$} will be referred to as a potential. It is often natural to describe two 
linearly independent solutions of \eref{eq:gen} using so-called phase-integral 
approximation. In the notation of Fr\"omans \cite{frbook}, it can be written as
\begin{eqnarray}
y_\pm = \predexp \exp [\pm \rmi \w(z)], \qquad \w(z)=\phsintgrl[\xi]{(z_0)}{z}.   \label{eq:phsint}
\end{eqnarray}
The function $\w(z)$ is the phase integral, and therefore we call $\phsintgrnd[\xi]$ 
the phase integrand. Also we will refer to $z_0$ as a basepoint. A meaning of the brackets in the 
lower limit of integration is a bit tricky; such a notation was introduced by Fr\"omans to make
phase integral look similar for all orders of approximation. In the first order this integral is just
a usual integral from $z_0$ to $z$. 

Provided that 
\begin{eqnarray}
\varepsilon = q^{-3/2} \rmd^2 q^{-1/2}/\rmd z^2  + (Q - q^2)/q \ll 1,   \label{eq:cond}
\end{eqnarray}
a general solution of \eref{eq:gen} can be approximated by
\begin{eqnarray}
y = c_+y_+ + c_-y_-. \label{eq:gensol}
\end{eqnarray}
Clearly, the inequality \eref{eq:cond} is not valid in a vicinity of poles or zeros of 
the phase integrand. Such points will be referred to as singular points and the 
vicinity of a singularity will be referred to as the interaction area.

Any phase-integral type solution \eref{eq:phsint} is a local, not global solution of \eref{eq:gen}. 
The method of phase integrals allows the construction of a globally defined 
asymptotic expression for the solution of a desired linear ordinary differential 
equation. The method was first proposed by A.Zwaan in his dissertation in 1929 \cite{zwaan}. 
He suggested allowing the independent variable in the differential equation to take 
complex values and to study a behaviour of the asymptotic solution far away from any 
singularities. According to Stokes\cite{stokes}, for any given exact solution 
of \eref{eq:gen} coefficients $c_+$ and $c_-$ in the approximate solution \eref{eq:gensol} 
differ from one domain of the complex plane to another 
(Stokes phenomenon \cite{stokes,white,heading,frbook}). Such abrupt 
changes happen on the so-called Stokes lines and have a form of a single-parameter 
linear transform\cite{heading}. The parameter associated with a particular Stokes line 
is called the Stokes constant. Knowing all Stokes constants associated with a particular 
potential gives the ability to obtain a globally defined approximate solution 
of \eref{eq:gen}\cite{heading,white} and the phase-integral method provides a simple 
way to find these constants and to write the solution. Unfortunately, there are very few 
cases when this method allows finding all the constants exactly, so approximations of different 
kinds are commonly used \cite{white,ours}. This happens mostly because of a lack of 
exact equations for the Stokes constants. In the present paper we provide a recipe to reduce the number 
of independent Stokes constants for a particular problem using symmetries of \eref{eq:gen}.

The paper is organized as follows. 
In \sref{sec:mtrxfrm} the matrix formulation of Heading`s rules is given. Such formulation appears
to be much more convenient for our purposes then the traditional one, which can be found, 
for example, in \cite{white}.
In \sref{sec:effsd} a concept of an effective Stokes diagram is presented. This concept is a natural
consequence of the matrix formulation. The idea of an effective Stokes constant is
essential for all following discussion on the subject of symmetry relations.
In \sref{sec:smmtrs} the symmetry relations are obtained from simple considerations. 
In \sref{sec:weber} the relations are used to find the exact form of reflection and 
transmission coefficients for the Weber equation. 
%In section \ref{BLCKHL} the relations are used for a problem with multiple parameters.
And, finally, in \sref{sec:cnclsns} are the conclusions. 

\section{Matrix formulation of the Heading`s rules of analytical continuation \label{sec:mtrxfrm}}
Let's start with some basic definitions. At every point $z$ of the complex plane except the 
singularities we will distinguish two orthogonal directions. Let's define the Stokes direction 
as a direction with $\Re \left[ \phsintgrnd \rmd z \right]=0$ and the anti-Stokes direction 
as a direction with $\Im \left[ \phsintgrnd \rmd z \right]=0$. We will also use a notion of 
the Stokes (anti-Stokes) field as a set of Stokes (anti-Stokes) directions for the entire 
complex plane. Following \cite{heading, white}, we introduce Stokes (anti-Stokes) lines as a 
paths along Stokes (anti-Stokes) field emanating from the potential`s singularities. 
Any domain of the complex plane bounded by the Stokes (anti-Stokes) lines and containing no other 
Stokes (anti-Stokes) lines will be referred to as the anti-Stokes (Stokes) domain. Particularly, if 
the potential $Q(z,\lmbd) \sim z^n$ as $z$ goes to complex infinity, then there are $n+2$ Stokes 
(anti-Stokes) domains in the vicinity of the infinity - we will call such domains the Stokes 
(anti-Stokes) wedges. Asymptotic phase-integral solutions \eref{eq:phsint} oscillate along anti-Stokes 
lines with equal amplitudes and increase (or decrease) exponentially with constant phase along Stokes lines. 
The increasing (decreasing) solution will be called dominant (subdominant) in a given Stokes domain. 
Strictly speaking, for every point except points of anti-Stokes lines the subdominant solution 
should be omitted since otherwise this results in over precision, but we will keep both functions 
everywhere according to the tradition. For the same reason we will assume, that the Stokes phenomenon 
occurs strictly on the Stokes line, although it can be detected only by comparing the asymptotic forms 
of the exact solution on the neighbouring anti-Stokes lines. Also, the complex plane with singular points
of the phase integrand, Stokes and anti-Stokes lines and branch cuts associated with a 
branching structure of asymptotic solutions \eref{eq:phsint} will be referred to as a Stokes diagram.

Usually, for any solution`s analytical continuation around the interaction area 
the Heading`s rules are used. These rules determine how the coefficients $c_\pm$ 
from \eref{eq:gensol} change from one anti-Stokes domain to another. A traditional presentation 
of these rules can be found in \cite{heading, white}. For us it is convenient to transform 
these rules into the matrix form for ease of reference.

Let's define a two-dimensional vector space consisting of vectors
%\[
\begin{eqnarray}
\psii= \left(\begin{array}{*{2}{c}} c_+ \\ c_- \end{array}\right).
\end{eqnarray}
%\]
Then assume that we have two neighbouring anti-Stokes domains $1$ and $2$, and there are 
corresponding $\psii$-vectors in the domains. Assume also that $y_+$ is dominant in the Stokes 
domain containing a borderline separating these anti-Stokes domains. 
In this situation we can relate $\psii_1$ and $\psii_2$ through the Stokes 
operator $\S$ in the following way:
\begin{eqnarray}
\psii_2 = \S[\pm s] \psii_1, \qquad 
\S[\pm s] = \left(\begin{array}{*{2}{c}} 1 & 0 \\ \pm s & 1 \end{array}\right),    
\end{eqnarray}
where $s$ is a Stokes constant. The sign of the Stokes constant as well as its value 
depends on the chosen base of approximate solutions $y_\pm$ and particularly on the 
basepoint $z_0$. We will use a plus sign if we cross the Stokes line in a counterclockwise 
direction relatively to the basepoint and a minus sign otherwise. If the borderline lies in 
a Stokes domain where $y_+$ is subdominant we must use $\S^{\Tp}$ instead of $\S$, where 'T' 
denotes the transpose operation.

Obviously, $\psii$-vector in a given anti-Stokes domain depends on the chosen basepoint too. 
As it follows from \eref{eq:phsint}, a change of the basepoint from $z_0=a$ to $z_0=b$ in 
terms of $\psii$-vectors can be written as
\begin{eqnarray}
\psii^{(b)} = \W[b,a] \psii^{(a)}, \qquad 
\W[b,a] =  
\left(\begin{array}{*{2}{c}}
\rme^{\rmi \phsintgrl{(a)}{(b)}} & 0 \\ 0 & \rme^{-\rmi \phsintgrl{(a)}{(b)}} 
\end{array}\right).
\end{eqnarray}
This is analogous to the reconnection formula in the traditional Heading`s form of the continuation 
rules and we will refer to the operator as a reconnection operator.
%Sometimes we will use the symbol $\W(w)=\W \left[\phsintgrl{a}{b} \right]$ to underline a value of the phase integral. 

Finally, we have to introduce a $\C$-operator associated with crossing a branch cut. The explicit form 
of the operator depends on the phase integrand $\phsintgrnd$. Here we derive it for the simplest case  
assuming $\phsintgrnd^2$ to be a single valued function. Imagine the cut emanating from the $k^{th}$ order
singularity of squared phase integrand (positive values of $k$ corresponds to zeros and negative to poles). 
Place this singularity into the origin. Then assume we want to cross the cut in the counterclockwise  
direction from domain $1$ to domain $2$. Then we have to change our variable 
from $z$ to $z \rme^{2\rmi\pi}$. Such a change will affect both pre-exponential 
slow $\predexp$ dependency and the phase integral in the exponent of the asymptotic 
base. Specifically, to implement these changes we have to replace $\predexp$ by $(-\rmi)^k \predexp$ 
and $\int \phsintgrnd \rmd z$ by $(-1)^k \int \phsintgrnd \rmd z$. In compact matrix form 
it can be written as
\begin{eqnarray}
\psii_2 = \C^k \psii_1, \qquad
\C =  \left(\begin{array}{*{2}{c}} 0 & -\rmi \\ -\rmi & 0 \end{array}\right).    \label{eq:C}
\end{eqnarray}
Analogous result was obtained in \cite{frbook}. Note that branching of the asymptotic solutions has nothing to do with an actual branching  of  an exact solution.
%As you can see, the need for the introduction of the $\C$-operator connected with the branching of the asymptotic solutions has nothing to do with a real branching structure of an exact solution. So, keeping in mind this simple rule we will omit any such cuts in the Stokes diagram and use cuts only to determine branches of $\phsintgrnd$ which is necessary for correct definition of phase integrals. 

\section{Effective Stokes diagram \label{sec:effsd}}
Imagine we have a Stokes domain with several Stokes lines emerging from the common basepoint.
Crossing this domain means multiple sequential applications of $\S$ or $\S^{\Tp}$ operators. But, as we
can make sure by a direct calculation, Stokes operators $\S$ as well as $\S^{\Tp}$ form a multiplicative
group:
\begin{eqnarray}
\S[s_2]\S[s_1] = \S[s_2 + s_1], \qquad
\S^{\Tp}[s_2]\S^{\Tp}[s_1] = \S^{\Tp}[s_2 + s_1].
\end{eqnarray}
It means that every such set of Stokes constants can be replaced by an effective one. It also means that
for any particular problem we will never need to know all these Stokes constants separately---the only
thing that matters is their sum.

Now let`s take a look at the reconnection operator $\W$. As it follows from 
the properties of the contour integral
in the complex plane, these operators in a given Stokes domain forms a multiplicative group too:
\begin{eqnarray}
\W[c,b]\W[b,a] = \W[c,a].
\end{eqnarray}
And, completely analogous to the situation discussed above, every set of sequential changes of the basepoint
can be replaced by the only one reconnection.

Finally, imagine a Stokes domain with multiple Stokes lines and multiple basepoints. Crossing this 
domain in terms of $\S$ and $\W$ operators looks something like
\begin{eqnarray}
\S[s_n]\W[a_n,a_{n-1}]\S[s_{n-1}]\W[a_{n-1},a_{n-2}]\ ...\ \S[s_1]\W[a_1,a_0]\S[s_0].
\end{eqnarray}
But we always can change an order of $\S$ and $\W$ operators because $\S[s']\W[b,a]=\W[b,a]\S[s'']$. Hence,
every such set of operators can always be replaced by only one combination $\S \W$ or, 
if someone prefer different ordering, $\W \S$. Consequently, every Stokes domain can be described by 
only one effective Stokes constant regardless how many Stokes lines it contains. The difference between 
this effective Stokes constant and the usual one appears in the limit of well-isolated singularities 
when the usual Stokes constant approaches its limiting value according to the approximation of 
isolated singularities while the effective one does not. However, as long as every effective Stokes 
constant can be expressed in terms of usual Stokes constants and corresponding phase integrals, we can 
still use the approximation of isolated singularities when we need it. Similarly, every set of 
anti-Stokes lines going in the same direction can be replaced by only one effective anti-Stokes line. 
Such a line now is just a borderline separating different Stokes domains. 

\begin{figure}
\centering
\noindent
\includegraphics[width=1.0\textwidth]{stuff/effsd_1.png}
\caption{
Stokes diagrams for $q(z,E)=\sqrt{z^4-E}$

1. A traditional Stokes diagram; dotes mark the zeros of the phase integrand

2. An effective Stokes diagram with a specified path of analytical continuation

3. An effective Stokes diagram with the same path of analytical continuation but different basepoints}
\label{fig:effsd_1}
\end{figure} 

A Stokes diagram consisting of effective Stokes and anti-Stokes lines will be referred to as 
an effective Stokes diagram (figures \ref{fig:effsd_1},\ref{fig:effsd_2}). 
As it follows from the previous discussion, effective diagram is not unique
and can be plotted differently depending on what path of analytical continuation was chosen---that is why
it is usually convenient to specify the path right on the diagram. But even when the path is chosen we
are still free to vary our basepoints` locations. Actually, the effective Stokes line can connect any two 
points of the corresponding Stokes domain if it does not destroy the topology of the entire 
Stokes diagram, taking into account the specifics of a particular problem. 
Choosing what points to connect by the effective Stokes line we will indicate what basepoints 
will be used in a given Stokes domain. Also it can be useful to indicate values of the phase integrals instead of
plotting multiple branch cuts.

One of the advantages of the effective Stokes diagram is that it is much simpler than the 
usual one---almost every Stokes (anti-Stokes) domain contains only one Stokes (anti-Stokes) line. 
Another advantage is that we can easily calculate how many independent unknowns our problem actually has. 

\begin{figure}
\centering
\noindent
\includegraphics[width=1.0\textwidth]{stuff/effsd_2.png}
\caption{
Stokes diagrams for $q(z,g)=\sqrt{-z + g^2/z}$

1. A traditional Stokes diagram; star marks the pole of the phase integrand. 

2. An effective Stokes diagram with a specified path of analytical continuation. 

3. An effective Stokes diagram with a different path of analytical continuation.
It is meaningful only if $g \gg 1$ and all the singularities are far away from each other---otherwise 
the phase-integral approximation itself fails between the pole and the right zero and the whole theory
becomes not applicable}
\label{fig:effsd_2}
\end{figure}  

The concept of the effective Stokes constant is crucial for the following discussion. 
In contrast to the traditional one such Stokes constant is always a measurable quantity
providing the phase-integral approximation is applicable; one 
can easily calculate it by comparing asymptotics of an exact solution on the 
neighbouring anti-Stokes lines. For the traditional Stokes constant it is present only if the
corresponding singularity is far away from any others. 
For example, let`s take a look at \fref{fig:effsd_2}. Comparing \fref{fig:effsd_2}.1 with \fref{fig:effsd_2}.2
one can notice that the effective Stokes constant $s$ is actually a combination of
two traditional constants $s_1$ and $s_2$. If we want to calculate, for example, $s_1$, we have to analytically
continue some solution of the corresponding equation along the path shown in  \fref{fig:effsd_2}.3. But
if the singularities are close to each other, the phase-integral approximation fails between the pole
and the right zero and $s_1$ looses its meaning. However, the phase-integral approximation still holds
far away from all the singularities and $s$ from \fref{fig:effsd_2} stays measurable and meaningful
although $s_1$ and $s_2$ cease to exist. That is why any exact symmetry relation can be written only 
for the effective Stokes constant.

\section{Symmetries and the corresponding connections between effective Stokes constants \label{sec:smmtrs}}
Let`s define what we mean by a symmetry of a given equation. Here we introduce three operators
$\f(z,\lmbd)$, $\g(z,\lmbd)$ and $\h(z,\lmbd)$ such that
\begin{eqnarray}
\f:\{y\} \rightarrow \{y\}, \qquad
\g:\{z\} \rightarrow \{z\}, \qquad
\h:\{\lmbd\} \rightarrow \{\lmbd\}.
\end{eqnarray}
Now, if we rewrite \eref{eq:gen} in operator form
\begin{eqnarray}
\L(z,\lmbd)y(z,\lmbd)=0, \qquad \L(z,\lmbd)=\frac{\rmd^2}{\rmd z^2} + Q(z,\lmbd),   \label{eq:L}
\end{eqnarray}
we can define any set of operators $\{\f,\g,\h\}$ as a symmetry transformation of \eref{eq:L} if
\begin{eqnarray}
\f(z,\lmbd)\L(\g(z,\lmbd)z,\h(z,\lmbd)\lmbd)=\L(z,\lmbd)\f(z,\lmbd).   \label{eq:symdef}
\end{eqnarray}
For example, an Airy operator $\L_{Airy}(z) = \rmd^2/\rmd z^2 - z$ has two base symmetries: 
$\{\g=\rme^{2 \rmi \pi/3}\unity,\f=\h=\unity\}$ and $\{\g=\unity,\f=c.c.,\h=c.c.\}$, where $\unity$ 
is a unity operator and $c.c.$ stands 
for complex conjugate. The main difference between these two symmetries is that the second 
one changes a direction of a complex variable`s phase increase and the first one does not. 
We will refer to the symmetries of the first kind as rotation symmetries and of the second 
kind as conjugation symmetries.

Definition \eref{eq:symdef} allows us to formulate the following statement: a linear solution space $\{y\}$ 
of \eref{eq:L} is invariant under the symmetry transformation. Indeed, for every $y(z,\lmbd)$
such that $\L(z,\lmbd)y(z,\lmbd)=0$ we can write
\begin{eqnarray}
0 \equiv \f\L(\g z,\h \lmbd)y(\g z,\h \lmbd)=
\L(z,\lmbd)\f y(\g z,\h \lmbd),   \label{eq:invrnt}
\end{eqnarray}
i.e. if $y(z,\lmbd)$ is a solution of \eref{eq:L} 
then $\tilde{y}(z,\lmbd)=\f(z,\lmbd)y(\g(z,\lmbd)z,\h(z,\lmbd)$ is another its solution.
It means that $\tilde{y}(z,\lmbd)$ as well as $y(z,\lmbd)$ can be written in the form \eref{eq:gensol}
but with different coefficients $c_\pm$. This difference and, as a consequence, 
restrictions on the Stokes constants can be determined directly by applying
the symmetry transformation to \eref{eq:phsint}, but we prefer more intuitive derivation.

Every symmetry transformation can be done in three consecutive steps: transformation 
of the parameters $\h(z,\lmbd)$, transformation of the independent variable $\g(z,\lmbd)$ and 
transformation of the whole expression $\f(z,\lmbd)$. 
Certainly, both rotation and conjugation symmetries can be discrete and 
usually are, but it is much more convenient to associate some continuous transformation 
with it. This can be done by introducing of an auxiliary variable $\mu$ varying from $0$ 
to $1$ such that, for example, $\g_{cont}(\mu)=\unity+\mu (\g-\unity)$, and $\g_{cont}(1)=\g$. 
As it will be seen from the following discussion the parametrization of the 
continuous operators can be important for the final result. Also we will assume that $\f$ can 
change the value of the Stokes constant but not the structure of the Stokes diagram and 
that is why it is not necessary to parametrize it. To determine how $\f$ acts on the 
Stokes constant it is enough to determine how it acts on the phase-integrals approximate 
solution \eref{eq:gensol} and how it changes the coefficients $c_\pm$.

\begin{figure}
\centering
\noindent
\includegraphics[scale=.5]{stuff/rs.png}
\caption{Stokes diagram`s evolution due to the symmetry transformation}
\label{fig:rst}
\end{figure}

To understand a consequences of the symmetry`s presence look at \fref{fig:rst}. 
First of all let`s keep track of the basepoints` movement under the continuous parameters` 
transformation $\h_{cont}(\mu)$. Usually it is convenient to choose some singularity of the 
potential as a basepoint, but the choice is not necessary for our discussion so we will assume 
only that it somehow depends on the set of the problem`s parameters $\lmbd$. As long as under 
this assumption our basepoint $a=a(\h_{cont}(\mu)\lmbd)=a(\mu)$, like the others, is a function 
of the auxiliary variable $\mu$, the whole Stokes diagram continuously changes preserving its 
initial topology while $\mu$ varies from 0 to 1. Assuming also that every Stokes constant is 
an analytical function of $\lmbd$, we finally arrive at the situation when each transformed Stokes 
line associates with a new value of the same Stokes constant $s(\h\lmbd)$. The result of this 
transformation is shown in \fref{fig:rst}.2. 

Then, we do the same with the independent variable $z$ using $\g_{cont}(\nu)$. Under this 
transformation the Stokes domains change places and one Stokes line is replaced by another one 
associated with some other Stokes constant $s'(\h\lmbd)$ (\fref{fig:rst}.3). Due to the symmetry 
of the problem and, particularly, to the consequences of \eref{eq:invrnt},
the final result of these two transformations` composition can differ from the initial 
configuration only by the basepoints` positions, and that is why $s'(\h\lmbd)$ 
and $s(\lmbd)$ have to be equal accurate to the corresponding phase integral and the $\f$ 
transformation.

Now we are ready to write the final relation for the Stokes constants. A formula
expressing this relation is shown below:
\begin{eqnarray}
\fl 
\S^{(\Tp)} \left[ \f s'(\h\lmbd) \right] = 
\W \left[ \g^{-1}a'(\h\lmbd),a(\lmbd) \right]
\S^{(\Tp)} \left[ s(\lmbd) \right]
\W \left[ a(\lmbd), \g^{-1} a'(\h\lmbd) \right],
\label{eq:gensym}
\end{eqnarray}
where $\S^{(\Tp)}$ can be either $\S$ or $\S^{\Tp}$. The chose in the right hand side 
of \eref{eq:gensym} must be maid on the basis of general rules from \sref{sec:mtrxfrm}: 
we use $\S$ for the Stokes domain associated with $s(\lmbd)$ if $y_+$ is dominant 
and $\S^{\Tp}$ otherwise. In the left hand side of \eref{eq:gensym} we have to use the 
same form as in the right hand side. An integration path in the formula can be determined 
in the following way: we have to decide what path we would use to change a basepoint 
from $a(\lmbd)$ to $a'(\lmbd)$ and then trace how it deforms under our transformation. 
And now we can see why and how a resulting symmetry relation can depend on the parametrization 
of the continuous operators: this dependency is a manifestation of a branching structure of 
the Stokes constant as a function of the problem`s parameters $\lmbd$.

The relation discussed above must be considered as a main result of the present paper.
It allows us to take a fresh look at the nature of the different Stokes constants. 
Two different Stokes domains which can be overlaid by the transformations $\{\g,\h\}$ are 
actually associated with the same effective Stokes constant but taken in the different 
points of the parameters` space. In particular, every set of Stokes wedges can be described 
by only one multidimensional analytical complex function $s(\lmbd)$.

Now let us take a closer look at the important special case of a complex conjugation symmetry. 
For every potential which is real on the real axes the symmetry $\f=\g=\h=c.c.$ holds, 
i.e. $\L^*(z^*,\lmbd^*)=\L(z,\lmbd)$ and
\begin{eqnarray}
\S^{(\Tp)} \left[ -s'^*(\lmbd^*) \right] = 
\W \left[ a'^*(\lmbd^*),a(\lmbd) \right]
\S^{(\Tp)} \left[ s(\lmbd) \right]
\W \left[ a(\lmbd),a'^*(\lmbd^*) \right].
\label{eq:cnjgtn}
\end{eqnarray}
A minus sign before the Stokes constant in the left hand side of \eref{eq:cnjgtn} is a result 
of the conjugation symmetry. It appears for any transformation $\g$ which changes the direction 
of a complex variable`s phase increase (\fref{fig:cst}). Strictly speaking, there should be two 
different general formulas for the rotation and conjugation symmetries, but it is convenient 
to agree to include this minus sign into the $\f$ operator acting on the Stokes constant.

\begin{figure}
\centering
\noindent
\includegraphics[scale=.5]{stuff/cs.png}
\caption{Stokes diagram`s evolution corresponding to the conjugation symmetry transformation when both conjugate Stokes lines have the same basepoint and $\g^{-1}a(\h\lmbd)=a(\lmbd)$}
\label{fig:cst}
\end{figure} 

If $a(\lmbd)=a'^*(\lmbd^*)$ as in \fref{fig:cst}, and $\lmbd$ is real, we obtain a result 
$s^*(\lmbd)=-s'(\lmbd)$ which can be inferred from the symmetry relations presented in \cite{symm}. 
If furthermore $s=s'$ we get an important and extremely simple relation $s^*(\lmbd)=-s(\lmbd)$, i.e. such Stokes constant is purely imaginary providing $\lmbd$ is real.

Another important case of \eref{eq:gensym} is a case with $\g=\unity$:
\begin{eqnarray}
\S^{(\Tp)} \left[ \f s(\h\lmbd) \right] = 
\W \left[ a(\h\lmbd),a(\lmbd) \right]
\S^{(\Tp)} \left[ s(\lmbd) \right]
\W \left[ a(\lmbd),a(\h\lmbd) \right].
\label{eq:func}
\end{eqnarray}
Such case is relevant for every potential. The obtained relation is a functional 
equation for the considered Stokes constant. Usually such equation helps to illuminate 
a branching structure of the Stokes constant and write it as a new single-valued function 
multiplied by the known multivalued one.

\section{Example: the Weber equation \label{sec:weber}}

\begin{figure}
\centering
\noindent
\includegraphics[scale=.5]{stuff/wsd.png}
\caption{Stokes field (1), anti-Stokes field (2) and a Stokes diagram (3) for the Weber equation ~\eref{eq:weber}}
\label{fig:wsd}
\end{figure} 

The best-known type of the phase-integral approximation is the WKBJ (and often simply WKB) approximation, 
so named after Wentzel, Kramers, Brillouin, and Jeffreys \cite{wkb1,wkb2,wkb3,wkbj}. 
It takes the form \eref{eq:phsint} with $\phsintgrnd = \sqrt{Q(z,\lmbd)}$. Since it is the simplest one
we will use it all throughout this section.

Let us consider the Weber equation
\begin{eqnarray}
\frac{\rmd^2 y(z)}{\rmd z^2}+(z^2-\delta^2)y(z)=0
\label{eq:weber}
\end{eqnarray}
with a boundary conditions of a presence of incident wave from the large negative $z$ and absence on such 
a wave from the large positive $z$. We define the reflection (transmission) coefficient $R$ ($T$) as
a ratio of the amplitudes of the reflected (transmitted) and incident waves. 
Our aim now is to find these scattering characteristics.

The boundary conditions can be written in terms of $\psii$-vectors as
\begin{eqnarray}
\psii_0 = \left(\begin{array}{*{2}{c}} 1 \\ 0 \end{array}\right),
\label{eq:wbound}
\end{eqnarray}
where $\psii_0$ is a $\psii$-vector in an anti-Stokes wedge containing a ray $Arg(z)=0$.
First of all, scattering characteristics must be written through the 
Stokes constants. To do this, we must analytically continue our boundary 
condition (\eref{eq:wbound}) to $z$ with $Arg(z)=\pi$. 
Using \fref{fig:wsd} and the rules from Sec.\sref{sec:mtrxfrm} we write
\begin{eqnarray}
\psii_{\pi} = 
\S \left[ s_{3/2} \right]
\W \left[ \rmi w(\delta) \right] 
\S^{\Tp} \left[ s_{1/2} \right] \psii_0 = 
\rme^{\rmi w(\delta)} \left(\begin{array}{*{2}{c}} 1 \\ s_{3/2} \end{array}\right),
\end{eqnarray}
where $w(\delta)=-\rmi\pi\delta^2/2$ is a phase integral calculated above the cut 
from $z=\delta$ to $z=-\delta$. Now we have to identify incident, reflected and transmitted waves. 
Since $y_+ \propto e^{\rmi z^2/2}$ hence it is 
an outgoing wave for $z \rightarrow +\infty$ as well as for $z \rightarrow -\infty$ and
\begin{eqnarray}
R = \frac{1}{s_{3/2}},\ T=\rmi\frac{\rme^{-\rmi w}}{s_{3/2}}.
\end{eqnarray}

To find $s_{3/2}$ let`s try a traditional method described, for example, in \cite{white}. We can obtain desired equations for the Stokes constants using the single-valuedness of the general solution and analytically continue it around the origin far away from the interaction area:
\begin{eqnarray}
\unity = 
\C^2
\S \left[ s_{3/2} \right]
\W \left[ \rmi w \right] 
\S^{\Tp} \left[ s_{1/2} \right]
\S \left[ s_{-1/2} \right]
\W \left[ \rmi w \right]
\S^{\Tp} \left[ s_{-3/2} \right],
\end{eqnarray}
from which follows
\begin{eqnarray}
\cases{
s_{1/2} = s_{-3/2}\\
s_{3/2} = s_{-1/2}\\ 
s_{1/2}s_{3/2} + e^{-2 \rmi w} + 1 = 0
}.
\label{eq:webtrad}
\end{eqnarray}
It is easy to see now that we cannot find $s_{3/2}$ from the system \eref{eq:webtrad} - 
we need at least one more restriction for the Stokes constants. In \cite{white} a 
requirement of the flux conservation is used and it gives $s_{-1/2}=-s_{1/2}^*$ - it helps 
to determine $|R|$, but its phase is unknown. Actually the flux conservation is a consequence 
of the real-valuedness and analyticity of the potential $x^2-\delta^2$ and hence the same 
relation can be obtained from the conjugation symmetry using \eref{eq:cnjgtn}. 
But it is not the only consequence of the equation`s symmetry, so let`s write them all.

First of all let`s try a rotation symmetry $\{\g=\rme^{\rmi\pi},\h=\f=\unity\}$ - 
it can relate $s_{\pm 3/2}$ with $s_{\mp 1/2}$. Take, for example, $s_{3/2}$ and $s_{-1/2}$. 
A basepoint of $s_{3/2}$ is chosen to be equal to $-\delta$ on the upper side of the cut 
and can be written as $b(\delta)=\delta \rme^{\rmi\pi}$. 
Obviously, $\g^{-1}b(\h\delta)=\rme^{-\rmi\pi}b(\delta)=\delta=a(\delta)$, where $a(\delta)$ 
is a basepoint of $s_{-1/2}$. According to \eref{eq:gensym}, it means that
\begin{eqnarray}
\S\left[ s_{3/2}(\delta) \right] = 
\W \left[ a(\delta), a(\delta) \right] 
\S \left[ s_{-1/2}(\delta) \right]
\W \left[ a(\delta), a(\delta) \right],
\end{eqnarray}
and
\begin{eqnarray}
s_{3/2}(\delta) = s_{-1/2}(\delta).
\label{eq:websym_1}
\end{eqnarray}
But we have already achieved this result (\Eref{eq:webtrad}) earlier! And it is clear 
because the corresponding symmetry is just a rotation - it can be seen even from the 
usual analytical continuation. Similarly, we can obtain $s_{1/2}(\delta)=s_{-3/2}(\delta)$, 
so, the only original equation in the system (\eref{eq:webtrad}) is the last one - 
it cannot be obtained from any other considerations.

Another rotation symmetry which can relate different Stokes constants is a symmetry 
$\{\g=\h=\rmi,\f=\unity\}$ - it can overlay, for example, 
$s_{1/2}$ and $s_{-1/2}$. Both of the Stokes constants have the same 
basepoint $a(\delta)=\delta$ and $\g^{-1}a(\h\delta)=(-\rmi)\rmi\delta=\delta$, so
\begin{eqnarray}
\S \left[ s_{1/2}(\rmi \delta) \right] = 
\W \left[ a(\delta), a(\delta) \right]
\S \left[ s_{-1/2}(\delta) \right]
\W \left[ a(\delta), a(\delta) \right],
\end{eqnarray}
or
\begin{eqnarray}
s_{1/2}(\rmi \delta) = s_{-1/2}(\delta).
\label{eq:websym_2}
\end{eqnarray}
Considering \eref{eq:websym_1} and another analogous relation, we can easily 
see now that all four Stokes wedges can be described by only one function as 
was mentioned in the previous section. 

Now let's take a look at the symmetry $\{\h=\rme^{\rmi\pi}\unity,\g=\f=\unity\}$ - as it was written in the previous section, such a symmetry gives rise to a functional equation which can help to illuminate a branching structure of the Stokes constant. 
For definiteness we will talk about $s_{3/2}$. To understand what to choose as endpoints in the phase integrals in \eref{eq:func}, let`s parametrize $\h$ as $\h_{cont}(\mu)=\rme^{\rmi\pi\mu}\unity$ and look at \fref{fig:webrs}. Obviously, for $s_{3/2}$ a basepoint $a(\delta)=\delta \rme^{\rmi\pi}$ and the question is how it is changing under our transformation. Using ~\fref{fig:webrs} we see that finally it arrives at $z=\delta$, but the phase matters because it defines a branch of the integrand $\sqrt{Q(z,\delta)}$ and that is why 
$a(\h\delta)=\delta \rme^{2\rmi\pi}$ and
\begin{eqnarray}
\S \left[ s_{3/2}(\delta \rme^{\rmi\pi}) \right] = 
\W \left[-\rmi w \right]
\S \left[ s_{3/2} (\delta) \right]
\W \left[ \rmi w \right],
\end{eqnarray}
or
\begin{eqnarray}
s_{3/2}(\delta \rme^{\rmi\pi})=s_{3/2}(\delta)\rme^{-2\rmi w}=s_{3/2}(\delta)e^{-\pi\delta^2}.
\label{eq:websym_3}
\end{eqnarray}
This functional equation can be easily solved by substitution 
$s_{3/2}(\delta)=\rmi\delta^{\rmi\delta^2}f(\delta^2)$, where $f(\delta^2)$
is single-valued in a sense $f(x)=f(x \rme^{2\rmi\pi})$.

\begin{figure}
\centering
\noindent
\includegraphics[scale=.5]{stuff/wrs.png}
\caption{Evolution of the Stokes field and effective Stokes lines 
under the continuous parameter`s transformation $\h_{cont}(\mu)=\rme^{\rmi\pi\mu}\unity$}
\label{fig:webrs}
\end{figure} 

And, finally, consider a conjugation symmetry $\f=\g=\h=c.c.$. This symmetry relates the Stokes constants in the upper half plane of the complex plane with the constants in the lower half plane. For example, according to \eref{eq:cnjgtn},
\begin{eqnarray}
\S \left[ -s_{1/2}^*(\delta^*) \right] = 
\W \left[ b^*(\delta^*),a(\delta) \right]
\S \left[ s_{-1/2}(\delta) \right]
\W \left[ a(\delta),b^*(\delta^*) \right],
\end{eqnarray}
and, since $b(\delta)=a(\delta)=\delta$,
\begin{eqnarray}
s_{1/2}^*(\delta^*)=-s_{-1/2}(\delta).
\label{eq:websym_4}
\end{eqnarray}
For real values of $\delta$ \eref{eq:websym_4} is nothing but the law of the flux conservation mentioned above. But, for complex values, in conjunction with \eref{eq:websym_3} and \eref{eq:websym_1} it gives
\begin{eqnarray}
s_{3/2}(\delta)=s_{-1/2}(\delta)=\rmi(\rmi \delta^2)^{\rmi \delta^2/2}p(\rmi \delta^2),
\label{eq:websym_5}
\end{eqnarray}
where $p(x)=p(x \rme^{2\rmi\pi})$ and $p(x)$ is real on the real axis. Now, using ~\eref{eq:websym_2} and the last equation from the system \eref{eq:webtrad}, we can write a functional equation for $p(x)$:
\begin{eqnarray}
p(x)p(-x)=2\cos(\pi x/2).
\label{eq:pfunc}
\end{eqnarray}
This functional equation is similar to Euler`s reflection formula and can be reduced to it by the substitutions
$x=1-2t$ and $p(x)=u(x)\sqrt{2\pi}/\Gamma(1/2+x/2)$, where $u(x)u(-x)=1$. The function $u(x)$ can be easily found from the boundary conditions for \eref{eq:pfunc}. Indeed, we know exactly \cite{white} that 
$s(0)=\rmi\sqrt{2}$ and we can assume, according to the approximation of isolated singularities, that every Stokes constant approaches an imaginary unit as $\delta$ goes to plus infinity. Taking into consideration \eref{eq:websym_5}, we can say that
\begin{eqnarray}
\cases{ 
p(0) = \sqrt{2} \\
p(x) \sim x^{-x/2}\ as\ x \rightarrow \pm \rmi \infty 
}.  
\end{eqnarray}
Using also the asymptotics of gamma function, we can finally write that $u(x)=(2e)^{-x/2}$ and
\begin{eqnarray}
s_{3/2}(\delta)=\rmi(\rmi\delta^2)^{\rmi\delta^2/2}
\frac{\sqrt{2\pi}(2\rme)^{-\rmi\delta^2/2}}{\Gamma(1/2+\rmi\delta^2/2)}.
\end{eqnarray}
This is an exact expression of the Stokes constant for the Weber problem - it can be verified using an exact solution of the \eref{eq:weber} as it was done in \cite{ours}.
    
%\section{Example 2: two-dimensional parameters` space and a black hole`s lifetime \label{BLCKHL}}

\section{Conclusion \label{sec:cnclsns}}

The method of phase integrals is a beautiful and powerful method of a linear ordinary 
differential equations` asymptotic analysis, but its range of applicability is highly 
restricted to relatively simple tasks. More complicated problems need additional equations 
for the Stokes constants and that is why different kinds of approximations 
\cite{white,ours} are usually used. The analysis, presented in this paper, 
allows the reader to find functional relations between different Stokes constants 
and thus to reduce the number of unknowns. We transformed Heading`s rules \cite{heading,white} 
into the matrix form to achieve simplicity and automate the procedure of analytical continuation. 
We also proposed the idea of an effective Stokes diagram which can be a useful tool 
for simplifying the computations in case of complicated equations. Effective Stokes constants 
are assumed to be analytical functions with respect to the problem`s parameters and undergo 
the Stokes phenomenon when the effective Stokes line ceases to coincide with the usual one. 
We showed that every differential equation has some trivial symmetries which generate nontrivial 
functional equations for the Stokes constants. The functional equations are likely to be as complex 
as the initial differential equation but can be used as a measure of the chosen approximation`s 
accuracy. 

The main result of the present work is the \eref{eq:gensym}. This result, like any other obtained in 
the article, is valid for any approximation of the phase integral type.

%\textbf{Acknowledgement}

\section*{References}
\begin{thebibliography}{30}

\bibitem{frbook} Fr\"oman N. and Fr\"oman P.O. \textit{Physical Problems Solved by the Phase-Integral Method} (Cambridge: Cambridge University Press, 2002)

\bibitem{zwaan} Zwaan A., \textit{Intensit\"aten im Ca-Funkenspektrum}, Academish proefschrift thesis (Utrecht, 1929)

\bibitem{stokes} Stokes, G. G., Trans. Camb. Phil. Soc. 10, 105 (1857).

\bibitem{white} R. B. White,
 {\it Asymptotic Analysis of Differential Equations}, Imperial College Press, 2010.

\bibitem{heading} J. Heading. {\it An Introduction to Phase Integral Methods} 
Wiley, NY (1962)

\bibitem{ours} R.B. White, A.Kutlin {\it Bound state energies using Phase integral methods} 

%\bibitem{froman1} Fr\"oman, N., and Fr\"oman, P. O., 1974, Ann Phys (NY) 83, 103–107. (Review: Zentralblatt
%f¨ur Mathematik und ihre Grenzgebiete, Mathematics Abstracts 279, 190–191, 1974.)
%
%\bibitem{froman2} Fr\"oman, N., and Fr\"oman, P. O., 1974, Nuovo Cim 20B, 121–132.

\bibitem{symm} Fr\"oman, N., Fr\"oman, P. O., and Lundborg, B., 1988b, Math Proc Camb Phil Soc 104, 181–191

\bibitem{wkb1} G. Wentzel, Zeit. f. Phys. \textbf{38}, 518 (1926).

\bibitem{wkb2} H. A. Kramers, Zeit. f. Phys. \textbf{39}, 828 (1926).

\bibitem{wkb3} L. Brillion, C. R. Acad. Sci. Paris \textbf{183}, 24 (1926).

\bibitem{wkbj} H. Jeffries, Philos. Mag. [7] 33, 451 (1942)

\end{thebibliography}
\end{document}
